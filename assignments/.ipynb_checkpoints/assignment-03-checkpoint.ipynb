{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 200px\" src=\"https://raw.githubusercontent.com/trivikverma/researchgroup/master/assets/media/logo.png\"> EPA-122A *Spatial* Data Science \n",
    "\n",
    "\n",
    "## Assignment 3: Prediction / Inference\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ``Instructions``\n",
    "\n",
    "This assignment puts together what you learned in **Weeks 6-7**. Assignment 3 will build upon what you did in Assignment 2.  \n",
    "\n",
    "_Note:_ Go through **labs and homeworks 05-06** before starting this assignment. \n",
    "\n",
    "#### 1.1 Submission\n",
    "\n",
    "Please submit the results by Brightspace under **Assignment 03**, using a single file as example,\n",
    "\n",
    "```text\n",
    "firstname_secondname_thirdname_lastname_03.html\n",
    "\n",
    "```\n",
    "\n",
    "**If your file is not named in lowercase letters as mentioned above, your assignment will not be read by the script that works to compile 200 assignments and you will miss out on the grades. I don't want that, so be exceptionally careful that you name it properly. Don't worry if you spelled your name incorrectly. I want to avoid a situation where I have 200 assignments all called assignment_03.html**\n",
    "\n",
    "Please **do not** submit any data or files other than the ``html file``.\n",
    "\n",
    "Don't worry about your submission _rendering without the images_ **after** you submitted the file on brightspace. That is a brigthspace related issue of viewing your own submission but when I download all assignments as a batch file, I get all your images and code as you intended to submit. So make sure that your html shows everything you want us to see **before you submit**. \n",
    "\n",
    "#### 1.2 How do you convert to HTML? \n",
    "\n",
    "There are 2 ways, \n",
    "\n",
    "1. from a running notebook, you can convert it into html by clicking on the file tab on the main menu of Jupyter Lab \n",
    "    * File &rightarrow; Export Notebooks as... &rightarrow; Export Notebook to HTML\n",
    "2. go to terminal or command line and type\n",
    "    * ``jupyter nbconvert --to html <notebook_name>.ipynb  ``\n",
    "\n",
    "#### 1.3 Learning Objectives\n",
    "\n",
    "This assignment is designed to support one learning objective. After completing the following exercises you will be able to:\n",
    "\n",
    "* Explain the outcome of your models and relate them to your hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Problem``\n",
    "\n",
    "`Problem Statement`: While we all aspire to minimise crime, poverty, segregation or other inequitable and undesirable outcomes in society, it is necessary to first understand the severity of the issue and some of the most contributing factors or complex patterns. It may come as a surprise, but a lot of these outcomes are onmipresent in many cities in the world. For example, each city has neighbourhoods that are quite poor, do not have access to public transport services or enough amenities and resources. Pinpointing the exact causes of such observations is impossible, as these are highly nuanced and complex issues. However, there are factors (such as gross income, economic disparity, liveability and government infrastructure/support) that can be used as indicators to research these complex problems. For example, it is widely believed that there’s an increase in pollution in regions that have a high levels of economic activity. What is more, these areas tend to cluster in space.\n",
    "\n",
    "`What we expect`: Consider your hypothesis from **assignment 02** as a basis for assignment 3. In this assignment you are tasked with inspecting either 1). if there are natural clusters or dimensions in your data (an unsupervised learning - clustering problem), or 2). factors that may be correlated and/or contributing to a variable of your interest in the data (e.g., pollution, poverty, economic activity, etc). \n",
    "You should explore the same datasets from assignment 02 (they are mentioned again for clarity, below). Perform exploratory data analysis, iteratively refine your questions and chosen datasets, and produce plots to understand and communicate your findings. You may have done most of the exploration in assignment 02, so **choosing the same hypothesis will save you time**. You should use the contents of assignment-02 and feel free to update it with the feedback received from the teacher. You are free to come up with a different hypothesis, but that would mean more time to go through data cleaning and EDA. **I strongly advise to build upon assignment-02 and make certain improvements based on the feedback received**. \n",
    "\n",
    "`Example`\n",
    "If I look at air pollution, I'd start by looking at surface-level factors that may be correlated with air pollution, the conditions of a region: presence of cars, presence of green space, economic activity (such as industry). I'd start thinking about the following non-exhaustive list of questions: \n",
    "- Is air pollution higher where there are more roads and cars? \n",
    "- Are there any characteristic clusters of high or low air pollution in space? \n",
    "- Is there any correlation at all with busy areas and the locations of air pollution? Or with green space and air pollution? \n",
    "- How should I measure the presence of economic activity of a region? \n",
    "\n",
    "`Assignment Goal`: Improving societal conditions for several communities is a complex, difficult, and slow process. You may not even have variables in your hypothesis that logically completely correlate with your variable of choice. But try! This is only practice. We want students to explore data and make statistical predictions in an area that is vastly affected by many confounding, real-world complex factors. The goal is for students to illustrate learned skills that align with our course goals. The primary goal of this project is to explain the outcomes of an event you observed and hypothesized in the SHRUG datasets related to India."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Data``\n",
    "\n",
    "During the last assignment, you have gathered and cleaned a dataset from the [SHRUG database](https://docs.devdatalab.org/) comprising of:\n",
    "1. Data on several (socio-economic/environmental) variables that you have chosen to explore your hypothesis;\n",
    "2. Shapefiles from SHRUG for the geographic level of your analysis (shrid, district, subdistrict).\n",
    "\n",
    "\n",
    "As with previous assignment, we encourage you to put the data in a convenient location on your computer or laptop, ideally in a folder called **data** which is next to this **jupyter notebook**. Make sure you’ve set your working directory in the [correct manner](https://www.delftstack.com/howto/python/relative-path-in-python/). These are a big files and it may take a while to load onto your laptop and into Python (running on the jupyter labs environment). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Critical Data Science``\n",
    "\n",
    "Throughout the assignment, you have to critically reflect on your choices during the Data Science process. To help you set-up your Critical Data Science process, we have provided you with a 'Guide on Critical Data Science'. Section 3.2 contains a step-by-step approach which each key considerations for each part of the data science process. The guide can be found [here](https://trivikverma.github.io/spatial-data-science/resources_index.html#a-guide-to-critical-data-science). \n",
    "\n",
    "The core of this assignment is predication and inference. You will do this by either doing a spatial regression or cluster analysis. Below we have listed several biases that could be important to consider while doing these analyses.\n",
    "- Biases in regression analysis:\n",
    "  - Confirmation bias/conducting multiple regressions until analysis yields results.\n",
    "  - heteroskedasticity/ autocorrelation\n",
    "  - Out-of-sample predictions (Predictions made by a model on data not used during the training of the model) \n",
    "- Biases in cluster analysis:\n",
    "    - Confirmation bias/conducting multiple clusterings until analysis yields results  \n",
    "    - Normalization bias \n",
    "    - Initialization bias (a priori choice of centroids)\n",
    "\n",
    "You will find some more questions which you can use to reflect on your data science choices below. These questions and the biases listed above are not an exhaustive list of things to consider. More reflections on your data science process are always encouraged! **For specific thematic questions, see the list of inouts we have given in the critical data science handbook.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Tasks``\n",
    "\n",
    "For your convenience, the assignment has been divided into the following tasks, \n",
    "\n",
    "0. Use Assignment 2 as a base for this assignment. Report on changes and refinements that you made. What parts did you improve upon? Why did you make these changes? \n",
    "1. Use EDA, plot results, and make refinements to your models. (assignment 2 can be used here as a basis for your models - save time and remember the process is not linear!). Shortly reflect on your dataset:\n",
    "    -  Would your analysis results change when you choose a different year for analysis? Could you export your analysis framework to another country and still receive reliable results? \n",
    "    - Motivate your final choice of variables. Did you change your set of variables compared to assignment 2? If yes, does that choice have an effect on your results and their validity? \n",
    "2. Build a regression or clustering model to analyse your hypothesis. Explain why you have chosen this specifc analysis for your hypothesis.\n",
    "    - If you choose the **regression approach**, perform error analyses, noting the best features, worst features, and any trends in supervised learning. Also reflect on the possibility of colinearity and/or interaction effects in your dataset. Is your model overfitted or underfitted? What steps would you take to mitigate this in the next iteration? Can you come up with a method to minimize the trade-offs between both risks? \n",
    "    - If you choose the **clustering approach**, explore which variables contribute the most to explaining the clusters using a principle component analysis. Report your results and provide in-depth analysis of the models using quick notes in markdown cells. Are your clusters accurately representing the relationship in the real world? Are your clusters happening due to random chance or bias in your clustering method? Reflect on your PCA: Would your results change if you chose more or less variables or if you used more or less iterations of the PCA? \n",
    "3. Discuss your results, model weaknesses and future ideas for improvements. Critically reflect on your conclusions. Highlight potential sources of error/bias when extrapolating your analysis results. What are the overall strengths and weaknesses of your models? Do you think that it is useful to run your analysis again with the other approach? What differences could there be? Continue to improve your model to the best of your abilities. Lastly, comment on any additional ideas you have for a model that may be able to perform better, even if these ideas are not possible by any model that we have learned about in the course – for example, explain what type of information you wish your model could use, and how do you wish it could leverage that information. This doesn’t have to be explained in mathematical terms or theory, but the goal is to think about current limitations of models and how you wish to improve upon them.\n",
    "*A tip: you can use variations in the year of the data to use extra data in your observations. Does your model work for year 2016 and predict or cluster well for 2017?*\n",
    "\n",
    "***Remember to always document your code! Justify everything you do (cleaning data, analysisng data, exploring data, defining hypothesis or measurements, etc.) using markdown cells as you go through the notebook.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Start your analysis``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
