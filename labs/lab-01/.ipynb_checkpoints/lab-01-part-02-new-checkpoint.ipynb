{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 200px\" src=\"https://raw.githubusercontent.com/trivikverma/researchgroup/master/assets/media/logo.png\"> EPA-122A Introduction to *Urban* Data Science \n",
    "\n",
    "\n",
    "## Lab 1 - part 2: Data, Grammar and Engineering\n",
    "\n",
    "**TU Delft**<br>\n",
    "**Q2 2023**<br>\n",
    "**Instructor:** Trivik Verma <br>\n",
    "**[Centre for Urban Science & Policy]( https://cusp.tbm.tudelft.nl/)** <br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This notebook elaborates on the previous session and shows some more advanced tricks that will allow you to perform data cleaning and processing in cases where the original source data used are not made available ready for analysis (as we did in the previous session). In particular, we will show how you can transform data downloaded from the internet into the table you used to explore population patterns in Liverpool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Learning Goals](#section0)\n",
    "* [Obtaining raw data: The Liverpool Census Data Pack](#section1)\n",
    "* [Preparing data: Creating the table from the previous notebook](#section2)\n",
    "* [Investigate the data: Delving deeper into the Census Data Pack](#section3)\n",
    "    * [Advanced extension (optional)](#section3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals  <a class=\"anchor\" id=\"section0\"></a>\n",
    "\n",
    "- Understand how to use the necessary tools to transform data into the desired format.\n",
    "- Develop an understanding about how to explore the data and extract useful information\n",
    "\n",
    "\n",
    "Before anything, let us import the libraries we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ensures visualizations are plotted inside the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import os               # This provides several system utilities\n",
    "import pandas as pd     # This is the workhorse of data munging in Python\n",
    "import geopandas as gpd # This is a wrapper around pandas that allows us to also handle spatial data \n",
    "import seaborn as sns   # This allows us to easily and beautifully plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining raw data: The Liverpool Census Data Pack  <a class=\"anchor\" id=\"section1\"></a>\n",
    "\n",
    "Throughout this notebook (and later on as well), we will use the [CDRC](https://cdrc.ac.uk/)'s Census Data Pack for the city of Liverpool ([link](https://data.cdrc.ac.uk/dataset/cdrc-2011-census-data-packs-for-local-authority-district-liverpool-e08000012)) and explore some of the city's socio-demogaphic characteristics. This is a large package crafted by the CDRC that brings together several Census tables in a consistent way for the city of Liverpool. We will only be able to use just a few of them but, since they are consistently organized, the procedure used should teach you how to explore other variables on your own. In particular, in this session, we will be using a table that lists **population by country of birth**.\n",
    "\n",
    "The pack is composed of two types of data: tabular and spatial. Tabular data are numerical tables that contain information relating to many socio-economic variables for different units (areas); spatial data contains the geometries of the areas in which Liverpool is divided into. Since there are many variables contained in several tables, that can be linked to more than one geography, the pack also includes two \"compass files\" that help you find what you are looking for: one table that lists and describes the different datasets available; and a much more detailed table that lists and describes each and every single variable available in the pack.\n",
    "\n",
    "The remainder assumes you have downloaded and unpacked the data. \n",
    "\n",
    "**IMPORTANT**: if you are working on a university lab computer, make sure to store the downloaded files (as well as the notebook) in the `M:` drive. This will ensure it is safe and does not get erased.\n",
    "\n",
    "Specify the path to the folder in the following cell, so you can correctly run the code without errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sandiego_tracts_varnames.json', 'sandiego_tracts.gpkg', 'SanDiego_.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important! You need to specify the path to the data in *your* machine\n",
    "# If you have placed the data folder in the same directory as this notebook,\n",
    "# you would do:\n",
    "# path = 'Liverpool/'\n",
    "# Now you may tweak the line below to reflect your proper path\n",
    "path = 'data/SanDiego'\n",
    "\n",
    "# Check to see if the path is correct and works. If you have set it \n",
    "# correctly, you should obtain the following list\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: the paths above might look different in your computer. It is the most important thing for reproducing your code on someone else's machine. So spend some time understanding where the files are and how to set that path. You will use this again in Q3 and Q4 of the programme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data: Creating the table from the previous notebook  <a class=\"anchor\" id=\"section2\"></a>\n",
    "\n",
    "It is not only that data are not ready to analyze when you get a hold on them. Sometimes, there is not such thing as *the dataset* to analyze. Instead, what you have is a collection of separated files, sometimes with different structures, that you need to bring together to begin with. This is one of the areas where a bit of scripting skills can help you a long way. While in a traditional point-and-click program like Microsoft Excel or SPSS, you would have to repeat the steps every time you wanted to incorporate a new dataset, with a bit of Python ninja tricks, you can write code that will do it for you as many times as you need.\n",
    "\n",
    "We will begin jumping straight into the analysis of population in Liverpool, organized by country of birth, at the Local Super Output Area (LSOA) level. Because the Census Data Pack contains a lot of data and very many different tables, you will have to bear with us and trust that what we are extracting is exactly the data of interest. This will speed up the process to walk through the reading, processing and manipulating of a dataset. Once you are familiar with these skills, the final section goes into how to explore the entire pack with more detail.\n",
    "\n",
    "To read a \"comma separated values\" (`.csv`) file, we can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/SanDiego_.csv', index_col='GEOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B25077_001E</th>\n",
       "      <th>B02001_002E</th>\n",
       "      <th>B01003_001E</th>\n",
       "      <th>B25003_003E</th>\n",
       "      <th>B25001_001E</th>\n",
       "      <th>B09019_006E</th>\n",
       "      <th>B09019_001E</th>\n",
       "      <th>B15003_002E</th>\n",
       "      <th>B25018_001E</th>\n",
       "      <th>B19083_001E</th>\n",
       "      <th>B01002_001E</th>\n",
       "      <th>B08303_001E</th>\n",
       "      <th>B19013_001E</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6073018300</th>\n",
       "      <td>37.1</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62500.0</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>2530.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>732900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073018601</th>\n",
       "      <td>41.2</td>\n",
       "      <td>5147.0</td>\n",
       "      <td>4069.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>5147.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>88165.0</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>473800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073017601</th>\n",
       "      <td>54.4</td>\n",
       "      <td>5595.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>1702.0</td>\n",
       "      <td>5595.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>110804.0</td>\n",
       "      <td>0.4985</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>930600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073019301</th>\n",
       "      <td>42.3</td>\n",
       "      <td>7026.0</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>7026.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>100539.0</td>\n",
       "      <td>0.4003</td>\n",
       "      <td>2351.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>478500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073018700</th>\n",
       "      <td>21.8</td>\n",
       "      <td>40402.0</td>\n",
       "      <td>30455.0</td>\n",
       "      <td>24143.0</td>\n",
       "      <td>40402.0</td>\n",
       "      <td>2456.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>41709.0</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>7523.0</td>\n",
       "      <td>7146.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>515570.896382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            B25077_001E  B02001_002E  B01003_001E  B25003_003E  B25001_001E  \\\n",
       "GEOID                                                                         \n",
       "6073018300         37.1       2590.0       2375.0       1299.0       2590.0   \n",
       "6073018601         41.2       5147.0       4069.0       1970.0       5147.0   \n",
       "6073017601         54.4       5595.0       4925.0       1702.0       5595.0   \n",
       "6073019301         42.3       7026.0       5625.0       3390.0       7026.0   \n",
       "6073018700         21.8      40402.0      30455.0      24143.0      40402.0   \n",
       "\n",
       "            B09019_006E  B09019_001E  B15003_002E  B25018_001E  B19083_001E  \\\n",
       "GEOID                                                                         \n",
       "6073018300        137.0          0.0      62500.0       0.5355       2530.0   \n",
       "6073018601        562.0         24.0      88165.0       0.4265       1633.0   \n",
       "6073017601        442.0         34.0     110804.0       0.4985       2308.0   \n",
       "6073019301        638.0         46.0     100539.0       0.4003       2351.0   \n",
       "6073018700       2456.0         23.0      41709.0       0.3196       7523.0   \n",
       "\n",
       "            B01002_001E  B08303_001E    B19013_001E  \n",
       "GEOID                                                \n",
       "6073018300        946.0          3.9  732900.000000  \n",
       "6073018601        335.0          6.5  473800.000000  \n",
       "6073017601        644.0          6.2  930600.000000  \n",
       "6073019301        462.0          6.6  478500.000000  \n",
       "6073018700       7146.0          5.4  515570.896382  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df) # as you can see, we have successfully converted the structure into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above tells us that we are handling a \"pandas data frame\". Similar to R's \"data.frame\" class, it is one of the most essential data structures in Python for data analysis, and we will use it intensively. Data frames are sophisticated costructs that can perform several advanced tasks and have many properties. We will be discovering them as we progress on the course but, for now, let us keep in mind they are tables, indexed on rows and columns that can support mixed data types and can be flexibly manipulated.\n",
    "\n",
    "Now we have read the file, we can inspect it. For example, to show the first lines of the table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now quickly check the dimensions of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(628, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['B25077_001E', 'B02001_002E', 'B01003_001E', 'B25003_003E',\n",
       "       'B25001_001E', 'B09019_006E', 'B09019_001E', 'B15003_002E',\n",
       "       'B25018_001E', 'B19083_001E', 'B01002_001E', 'B08303_001E',\n",
       "       'B19013_001E'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implies 628 rows by 13 columns. That is a lot of columns, all named under obscure codes. For now, just trust that the columns we want are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['B01003_001E', 'B19083_001E', 'B01002_001E', 'B15003_002E', 'B25001_001E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep only those with us, we can *slice* the table using the `loc` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B01003_001E</th>\n",
       "      <th>B19083_001E</th>\n",
       "      <th>B01002_001E</th>\n",
       "      <th>B15003_002E</th>\n",
       "      <th>B25001_001E</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6073018300</th>\n",
       "      <td>2375.0</td>\n",
       "      <td>2530.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>62500.0</td>\n",
       "      <td>2590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073018601</th>\n",
       "      <td>4069.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>88165.0</td>\n",
       "      <td>5147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073017601</th>\n",
       "      <td>4925.0</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>110804.0</td>\n",
       "      <td>5595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073019301</th>\n",
       "      <td>5625.0</td>\n",
       "      <td>2351.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>100539.0</td>\n",
       "      <td>7026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073018700</th>\n",
       "      <td>30455.0</td>\n",
       "      <td>7523.0</td>\n",
       "      <td>7146.0</td>\n",
       "      <td>41709.0</td>\n",
       "      <td>40402.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            B01003_001E  B19083_001E  B01002_001E  B15003_002E  B25001_001E\n",
       "GEOID                                                                      \n",
       "6073018300       2375.0       2530.0        946.0      62500.0       2590.0\n",
       "6073018601       4069.0       1633.0        335.0      88165.0       5147.0\n",
       "6073017601       4925.0       2308.0        644.0     110804.0       5595.0\n",
       "6073019301       5625.0       2351.0        462.0     100539.0       7026.0\n",
       "6073018700      30455.0       7523.0       7146.0      41709.0      40402.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the columns with names in the list `variables`\n",
    "sub_df = df.loc[:, variables]\n",
    "\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we use the operator `loc` (for locator) on the dataframe, followed by squared brackets and, inside it, two alternatives: \n",
    "\n",
    "* We can use `:` to keep *all* the elements (rows in this case).\n",
    "* And we can use a list of strings (or simply one would work too) with the names what we want to select.\n",
    "\n",
    "We can further inspect the dataset with an additional command called `info`, that lists the names of the columns and how many non-null elements each contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 628 entries, 6073018300 to 6073021000\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   B01003_001E  628 non-null    float64\n",
      " 1   B19083_001E  628 non-null    float64\n",
      " 2   B01002_001E  628 non-null    float64\n",
      " 3   B15003_002E  628 non-null    float64\n",
      " 4   B25001_001E  628 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 29.4 KB\n"
     ]
    }
   ],
   "source": [
    "sub_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**[Renaming columns]**\n",
    "\n",
    "**IMPORTANT**: some of the elements in this part are more advanced hence optional. If you want to move quickly through the lab, simply run the code cells without paying much attention to what it does. Once you have become more familiar with the rest of the tutorial, return here and work through the logic.\n",
    "\n",
    "The table we have compiled contains exactly what we wanted. However, the names of the columns are a bit unintuitive, to say the least. It would be much handier if we could rename the columns into something more human readable. The easiest way to do that in `pandas` is by creating a dictionary that maps the original name into the desired one, and then applying it to the `DataFrame` with the command `rename`. Let us walk through the steps necessary, one by one:\n",
    "\n",
    "* Create a dictionary that maps the codes to the names. For this, we can use the list we have created before (`region_variables`), and what we have learnt about querying tables, combined with a small `for` loop.\n",
    "\n",
    "First we need to bring up the variable names into a separate table (see the final section for more detail):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file with variable descriptions\n",
    "vars = pd.read_json(path+'/sandiego_tracts_varnames.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>concept</th>\n",
       "      <th>short_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B25077_001E</th>\n",
       "      <td>Estimate!!Median value (dollars)</td>\n",
       "      <td>MEDIAN VALUE (DOLLARS)</td>\n",
       "      <td>median_house_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B02001_002E</th>\n",
       "      <td>Estimate!!Total!!White alone</td>\n",
       "      <td>RACE</td>\n",
       "      <td>total_pop_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01003_001E</th>\n",
       "      <td>Estimate!!Total</td>\n",
       "      <td>TOTAL POPULATION</td>\n",
       "      <td>total_pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B25003_003E</th>\n",
       "      <td>Estimate!!Total!!Renter occupied</td>\n",
       "      <td>TENURE</td>\n",
       "      <td>total_rented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B25001_001E</th>\n",
       "      <td>Estimate!!Total</td>\n",
       "      <td>HOUSING UNITS</td>\n",
       "      <td>total_housing_units</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B09019_006E</th>\n",
       "      <td>Estimate!!Total!!In households!!In family hous...</td>\n",
       "      <td>HOUSEHOLD TYPE (INCLUDING LIVING ALONE) BY REL...</td>\n",
       "      <td>hh_female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B09019_001E</th>\n",
       "      <td>Estimate!!Total</td>\n",
       "      <td>HOUSEHOLD TYPE (INCLUDING LIVING ALONE) BY REL...</td>\n",
       "      <td>hh_total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B15003_002E</th>\n",
       "      <td>Estimate!!Total!!No schooling completed</td>\n",
       "      <td>EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 Y...</td>\n",
       "      <td>total_bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B25018_001E</th>\n",
       "      <td>Estimate!!Median number of rooms</td>\n",
       "      <td>MEDIAN NUMBER OF ROOMS</td>\n",
       "      <td>median_no_rooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B19083_001E</th>\n",
       "      <td>Estimate!!Gini Index</td>\n",
       "      <td>GINI INDEX OF INCOME INEQUALITY</td>\n",
       "      <td>income_gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01002_001E</th>\n",
       "      <td>Estimate!!Median age!!Total</td>\n",
       "      <td>MEDIAN AGE BY SEX</td>\n",
       "      <td>median_age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B08303_001E</th>\n",
       "      <td>Estimate!!Total</td>\n",
       "      <td>TRAVEL TIME TO WORK</td>\n",
       "      <td>tt_work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B19013_001E</th>\n",
       "      <td>Estimate!!Median household income in the past ...</td>\n",
       "      <td>MEDIAN HOUSEHOLD INCOME IN THE PAST 12 MONTHS ...</td>\n",
       "      <td>median_hh_income</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         label  \\\n",
       "var_id                                                           \n",
       "B25077_001E                   Estimate!!Median value (dollars)   \n",
       "B02001_002E                       Estimate!!Total!!White alone   \n",
       "B01003_001E                                    Estimate!!Total   \n",
       "B25003_003E                   Estimate!!Total!!Renter occupied   \n",
       "B25001_001E                                    Estimate!!Total   \n",
       "B09019_006E  Estimate!!Total!!In households!!In family hous...   \n",
       "B09019_001E                                    Estimate!!Total   \n",
       "B15003_002E            Estimate!!Total!!No schooling completed   \n",
       "B25018_001E                   Estimate!!Median number of rooms   \n",
       "B19083_001E                               Estimate!!Gini Index   \n",
       "B01002_001E                        Estimate!!Median age!!Total   \n",
       "B08303_001E                                    Estimate!!Total   \n",
       "B19013_001E  Estimate!!Median household income in the past ...   \n",
       "\n",
       "                                                       concept  \\\n",
       "var_id                                                           \n",
       "B25077_001E                             MEDIAN VALUE (DOLLARS)   \n",
       "B02001_002E                                               RACE   \n",
       "B01003_001E                                   TOTAL POPULATION   \n",
       "B25003_003E                                             TENURE   \n",
       "B25001_001E                                      HOUSING UNITS   \n",
       "B09019_006E  HOUSEHOLD TYPE (INCLUDING LIVING ALONE) BY REL...   \n",
       "B09019_001E  HOUSEHOLD TYPE (INCLUDING LIVING ALONE) BY REL...   \n",
       "B15003_002E  EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 Y...   \n",
       "B25018_001E                             MEDIAN NUMBER OF ROOMS   \n",
       "B19083_001E                    GINI INDEX OF INCOME INEQUALITY   \n",
       "B01002_001E                                  MEDIAN AGE BY SEX   \n",
       "B08303_001E                                TRAVEL TIME TO WORK   \n",
       "B19013_001E  MEDIAN HOUSEHOLD INCOME IN THE PAST 12 MONTHS ...   \n",
       "\n",
       "                      short_name  \n",
       "var_id                            \n",
       "B25077_001E   median_house_value  \n",
       "B02001_002E      total_pop_white  \n",
       "B01003_001E            total_pop  \n",
       "B25003_003E         total_rented  \n",
       "B25001_001E  total_housing_units  \n",
       "B09019_006E            hh_female  \n",
       "B09019_001E             hh_total  \n",
       "B15003_002E       total_bachelor  \n",
       "B25018_001E      median_no_rooms  \n",
       "B19083_001E          income_gini  \n",
       "B01002_001E           median_age  \n",
       "B08303_001E              tt_work  \n",
       "B19013_001E     median_hh_income  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a \"dictionary\" to store names of the variables\n",
    "# and their description\n",
    "code2name = {}\n",
    "\n",
    "# Set the index to be the code of each variable\n",
    "lookup_table = vars.set_index('var_id') # Reindex to be able to query\n",
    "lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B01003_001E': 'total_pop',\n",
       " 'B19083_001E': 'income_gini',\n",
       " 'B01002_001E': 'median_age',\n",
       " 'B15003_002E': 'total_bachelor',\n",
       " 'B25001_001E': 'total_housing_units'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run over every region code, select its description/name and store it \n",
    "# in the `code2name` dictionary\n",
    "for code in variables:\n",
    "    code2name[code] = lookup_table.loc[code, 'short_name']\n",
    "code2name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With the dictionary in hand, renaming the columns can be done by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_pop</th>\n",
       "      <th>income_gini</th>\n",
       "      <th>median_age</th>\n",
       "      <th>total_bachelor</th>\n",
       "      <th>total_housing_units</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6073018300</th>\n",
       "      <td>2375.0</td>\n",
       "      <td>2530.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>62500.0</td>\n",
       "      <td>2590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073018601</th>\n",
       "      <td>4069.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>88165.0</td>\n",
       "      <td>5147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073017601</th>\n",
       "      <td>4925.0</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>110804.0</td>\n",
       "      <td>5595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073019301</th>\n",
       "      <td>5625.0</td>\n",
       "      <td>2351.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>100539.0</td>\n",
       "      <td>7026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073018700</th>\n",
       "      <td>30455.0</td>\n",
       "      <td>7523.0</td>\n",
       "      <td>7146.0</td>\n",
       "      <td>41709.0</td>\n",
       "      <td>40402.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_pop  income_gini  median_age  total_bachelor  \\\n",
       "GEOID                                                            \n",
       "6073018300     2375.0       2530.0       946.0         62500.0   \n",
       "6073018601     4069.0       1633.0       335.0         88165.0   \n",
       "6073017601     4925.0       2308.0       644.0        110804.0   \n",
       "6073019301     5625.0       2351.0       462.0        100539.0   \n",
       "6073018700    30455.0       7523.0      7146.0         41709.0   \n",
       "\n",
       "            total_housing_units  \n",
       "GEOID                            \n",
       "6073018300               2590.0  \n",
       "6073018601               5147.0  \n",
       "6073017601               5595.0  \n",
       "6073019301               7026.0  \n",
       "6073018700              40402.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename each column in `lsoa_orig_sub` from its code to its name\n",
    "sub_df = sub_df.rename(columns=code2name)\n",
    "\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is it! The table stored in `lsoa_orig_sub` is essentially the same as we played with in the previous session.\n",
    "\n",
    "## Investigate the data: Delving deeper into the Census Data Pack  <a class=\"anchor\" id=\"section3\"></a>\n",
    "\n",
    "We started this notebook assuming we already knew what variables in particular we wanted, out of the hundreds available on the Liverpool Census Data Pack. Unfortunately, that is not always the case, and sometimes  you have to explore an entire dataset by yourself to find what you are looking for. To dip your toes into the sea of the Census Data Pack, in this section we will walk through how to systematically identify a variable and extract it.\n",
    "\n",
    "The folder contains data at different scales. We will be using the Local Super Output Area (LSOAs). The folder is structured in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sandiego_tracts_varnames.json', 'sandiego_tracts.gpkg', 'SanDiego_.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This command lists the files in the folder passed (`path` in this case)\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will ignore the spatial information contained in the folder `shapefiles` and focus on the `tables` one. If you have a peek at the folder, it contains many files. You can get their names into a Python list with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/SanDiegotables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/philip/Library/CloudStorage/GoogleDrive-philip.mueller.bueckeburg@gmail.com/.shortcut-targets-by-id/1aQq3cTfZFIdOXJ2-gpuCTMJU1uLBiYH7/Spatial Data Science/2023/Assignments/Labs/lab-01/lab-01-part-02-new.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/philip/Library/CloudStorage/GoogleDrive-philip.mueller.bueckeburg%40gmail.com/.shortcut-targets-by-id/1aQq3cTfZFIdOXJ2-gpuCTMJU1uLBiYH7/Spatial%20Data%20Science/2023/Assignments/Labs/lab-01/lab-01-part-02-new.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create a list with the names of all the tables available\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/philip/Library/CloudStorage/GoogleDrive-philip.mueller.bueckeburg%40gmail.com/.shortcut-targets-by-id/1aQq3cTfZFIdOXJ2-gpuCTMJU1uLBiYH7/Spatial%20Data%20Science/2023/Assignments/Labs/lab-01/lab-01-part-02-new.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m csvs \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtables\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/SanDiegotables'"
     ]
    }
   ],
   "source": [
    "# Create a list with the names of all the tables available\n",
    "csvs = os.listdir(path + 'tables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And count them using the core fuction `len`, which returns the length of a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the length of the list `csvs`\n",
    "len(csvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is right, 303 files! Luckily, to navigate that sea of seemingly non-sensical letters, there is a codebook that explains things a bit. You can open it with a text editor or a spreadsheet program but, since it is a `csv` file, we can also ingest it with Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the file and set the first column as index\n",
    "codebook = pd.read_csv(path + 'datasets_description.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we have read the file, we can inspect it. For example, to show the first lines of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DatasetTitle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DatasetId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CT0010</th>\n",
       "      <td>Ethnic group write-ins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KS101EW</th>\n",
       "      <td>Usual resident population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KS102EW</th>\n",
       "      <td>Age structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KS103EW</th>\n",
       "      <td>Marital and civil partnership status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KS104EW</th>\n",
       "      <td>Living arrangements</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   DatasetTitle\n",
       "DatasetId                                      \n",
       "CT0010                   Ethnic group write-ins\n",
       "KS101EW               Usual resident population\n",
       "KS102EW                           Age structure\n",
       "KS103EW    Marital and civil partnership status\n",
       "KS104EW                     Living arrangements"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebook.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the index chosen to query rows. For example, if we want to see what dataset code `QS203EW` corresponds to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Country of birth (detailed)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the value for the column `DatasetTitle` and the row `QS203EW`\n",
    "# This is effectively the name of the dataset with that code\n",
    "codebook.loc['QS203EW', 'DatasetTitle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see what that dataset contains, there is another file in the folder called `variables_description.csv` that has further information. We can bring it in the same way we did before and, again, we will index it using the first column of the table, the ID of the dataset where the variable belongs to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = pd.read_csv(path+'variables_description.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a sense of how large it is, we can call its `shape` property, which returns the number of rows and columns, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2563, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the dimensions of the table `variables`\n",
    "variables.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2,563 different variables!!! Let us see what the structure of the table is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnVariableCode</th>\n",
       "      <th>ColumnVariableMeasurementUnit</th>\n",
       "      <th>ColumnVariableDescription</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DatasetId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CT0010</th>\n",
       "      <td>CT00100001</td>\n",
       "      <td>Count</td>\n",
       "      <td>All categories: Ethnic group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT0010</th>\n",
       "      <td>CT00100002</td>\n",
       "      <td>Count</td>\n",
       "      <td>English/Welsh/Scottish/Northern Irish/British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT0010</th>\n",
       "      <td>CT00100003</td>\n",
       "      <td>Count</td>\n",
       "      <td>Irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT0010</th>\n",
       "      <td>CT00100004</td>\n",
       "      <td>Count</td>\n",
       "      <td>Gypsy or Irish Traveller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT0010</th>\n",
       "      <td>CT00100005</td>\n",
       "      <td>Count</td>\n",
       "      <td>Other White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ColumnVariableCode ColumnVariableMeasurementUnit  \\\n",
       "DatasetId                                                    \n",
       "CT0010            CT00100001                         Count   \n",
       "CT0010            CT00100002                         Count   \n",
       "CT0010            CT00100003                         Count   \n",
       "CT0010            CT00100004                         Count   \n",
       "CT0010            CT00100005                         Count   \n",
       "\n",
       "                               ColumnVariableDescription  \n",
       "DatasetId                                                 \n",
       "CT0010                      All categories: Ethnic group  \n",
       "CT0010     English/Welsh/Scottish/Northern Irish/British  \n",
       "CT0010                                             Irish  \n",
       "CT0010                          Gypsy or Irish Traveller  \n",
       "CT0010                                       Other White  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are interested in exploring the country of birth (code `QS203EW`), we can subset the table using `loc` in a similar way as before. The only difference is that now we do not want to restrict the column to only one, so we use the colon `:` instead of a particular name, including thus *all* the columns. Let us also save the subset by assigning it to a new object, `birth_orig`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all the column values for the row `QS203EW`\n",
    "birth_orig = variables.loc['QS203EW', :]\n",
    "\n",
    "birth_orig.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be clear, the table above contains all the variables that the dataset `QS203EW` is comprised of. This means that, for every row in this table, there is a column in the actual dataset which, for the LSOAs, is on the file `QS203EW_lsoa11.csv`, in the `tables` folder.\n",
    "\n",
    "This is still a lot. Arguably, to get a first sense of the data and start exploring it, we do not need every single disaggregation available. Let us look at the names and codes of the first 25 variables to see if we can spot any pattern that helps us simplify (note how we now use `:` first to indicate we want *all* the rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnVariableCode</th>\n",
       "      <th>ColumnVariableDescription</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DatasetId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0001</td>\n",
       "      <td>All categories: Country of birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0002</td>\n",
       "      <td>Europe: Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0003</td>\n",
       "      <td>Europe: United Kingdom: Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0004</td>\n",
       "      <td>Europe: United Kingdom: England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0005</td>\n",
       "      <td>Europe: United Kingdom: Northern Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0006</td>\n",
       "      <td>Europe: United Kingdom: Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0007</td>\n",
       "      <td>Europe: United Kingdom: Wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0008</td>\n",
       "      <td>Europe: Great Britain not otherwise specified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0009</td>\n",
       "      <td>Europe: United Kingdom not otherwise specified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0010</td>\n",
       "      <td>Europe: Guernsey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0011</td>\n",
       "      <td>Europe: Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0012</td>\n",
       "      <td>Europe: Channel Islands not otherwise specified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0013</td>\n",
       "      <td>Europe: Isle of Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0014</td>\n",
       "      <td>Europe: Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0015</td>\n",
       "      <td>Europe: Other Europe: Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0016</td>\n",
       "      <td>Europe: Other Europe: EU Countries: Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0017</td>\n",
       "      <td>Europe: Other Europe: EU countries: Member cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0018</td>\n",
       "      <td>Europe: Other Europe: EU countries: Member cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0019</td>\n",
       "      <td>Europe: Other Europe: EU countries: Member cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0020</td>\n",
       "      <td>Europe: Other Europe: EU countries: Member cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0021</td>\n",
       "      <td>Europe: Other Europe: EU countries: Member cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0022</td>\n",
       "      <td>Europe: Other Europe: EU countries: Member cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0023</td>\n",
       "      <td>Europe: Other Europe: EU countries: Member cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0024</td>\n",
       "      <td>Europe: Other Europe: EU countries: Accession ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QS203EW</th>\n",
       "      <td>QS203EW0025</td>\n",
       "      <td>Europe: Other Europe: EU countries: Accession ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ColumnVariableCode  \\\n",
       "DatasetId                      \n",
       "QS203EW          QS203EW0001   \n",
       "QS203EW          QS203EW0002   \n",
       "QS203EW          QS203EW0003   \n",
       "QS203EW          QS203EW0004   \n",
       "QS203EW          QS203EW0005   \n",
       "QS203EW          QS203EW0006   \n",
       "QS203EW          QS203EW0007   \n",
       "QS203EW          QS203EW0008   \n",
       "QS203EW          QS203EW0009   \n",
       "QS203EW          QS203EW0010   \n",
       "QS203EW          QS203EW0011   \n",
       "QS203EW          QS203EW0012   \n",
       "QS203EW          QS203EW0013   \n",
       "QS203EW          QS203EW0014   \n",
       "QS203EW          QS203EW0015   \n",
       "QS203EW          QS203EW0016   \n",
       "QS203EW          QS203EW0017   \n",
       "QS203EW          QS203EW0018   \n",
       "QS203EW          QS203EW0019   \n",
       "QS203EW          QS203EW0020   \n",
       "QS203EW          QS203EW0021   \n",
       "QS203EW          QS203EW0022   \n",
       "QS203EW          QS203EW0023   \n",
       "QS203EW          QS203EW0024   \n",
       "QS203EW          QS203EW0025   \n",
       "\n",
       "                                   ColumnVariableDescription  \n",
       "DatasetId                                                     \n",
       "QS203EW                     All categories: Country of birth  \n",
       "QS203EW                                        Europe: Total  \n",
       "QS203EW                        Europe: United Kingdom: Total  \n",
       "QS203EW                      Europe: United Kingdom: England  \n",
       "QS203EW             Europe: United Kingdom: Northern Ireland  \n",
       "QS203EW                     Europe: United Kingdom: Scotland  \n",
       "QS203EW                        Europe: United Kingdom: Wales  \n",
       "QS203EW        Europe: Great Britain not otherwise specified  \n",
       "QS203EW       Europe: United Kingdom not otherwise specified  \n",
       "QS203EW                                     Europe: Guernsey  \n",
       "QS203EW                                       Europe: Jersey  \n",
       "QS203EW      Europe: Channel Islands not otherwise specified  \n",
       "QS203EW                                  Europe: Isle of Man  \n",
       "QS203EW                                      Europe: Ireland  \n",
       "QS203EW                          Europe: Other Europe: Total  \n",
       "QS203EW            Europe: Other Europe: EU Countries: Total  \n",
       "QS203EW    Europe: Other Europe: EU countries: Member cou...  \n",
       "QS203EW    Europe: Other Europe: EU countries: Member cou...  \n",
       "QS203EW    Europe: Other Europe: EU countries: Member cou...  \n",
       "QS203EW    Europe: Other Europe: EU countries: Member cou...  \n",
       "QS203EW    Europe: Other Europe: EU countries: Member cou...  \n",
       "QS203EW    Europe: Other Europe: EU countries: Member cou...  \n",
       "QS203EW    Europe: Other Europe: EU countries: Member cou...  \n",
       "QS203EW    Europe: Other Europe: EU countries: Accession ...  \n",
       "QS203EW    Europe: Other Europe: EU countries: Accession ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all the rows for the two columns 'ColumnVariableCode' and\n",
    "# 'ColumnVariableDescription', and show the top 25\n",
    "birth_orig.loc[:, ['ColumnVariableCode', 'ColumnVariableDescription']].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we have been able to pass a list of variables we wanted to select as columns, and `pandas` has returned the dataframe \"sliced\" with only those, cutting off the rest.\n",
    "\n",
    "It looks like the variable name follows a hierarchical pattern that dissaggregates by regions of the world. A sensible first approach might be to start considering only the largest regions. To do that, we need a list of the variable name for those aggregates since, once we have it, subsetting the dataframe will be straightforward. There are several ways we can go about it:\n",
    "\n",
    "* Since there are not that many regions, we can hardcode them into a list, the same we have used above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_codes = ['QS203EW0002', 'QS203EW0032', 'QS203EW0045', \\\n",
    "                'QS203EW0063', 'QS203EW0072']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Advanced extension (optional)  <a class=\"anchor\" id=\"section3_1\"></a>\n",
    "\n",
    "* However, this approach would not get us very far if the list was longer. For that, a much more useful way is to write a loop that builds the list for us. To do this, we can remember some of the tricks learnt in the previous session about writing `for` loops and `if` statements and combine them with new ones about working with strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Europe: Total',\n",
       " 'Africa: Total',\n",
       " 'Middle East and Asia: Total',\n",
       " 'The Americas and the Caribbean: Total',\n",
       " 'Antarctica and Oceania: Total']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions = []\n",
    "for var in birth_orig['ColumnVariableDescription']:\n",
    "    # Split the name of the variable in pieces by ': '\n",
    "    pieces = var.split(': ')\n",
    "    # Keep the first one (top hierarchy) and append ': Total'\n",
    "    name = pieces[0] + ': Total'\n",
    "    # If the name created matches the variable (i.e, it exists in the original list), \n",
    "    # add the name to the list\n",
    "    if name == var:\n",
    "        regions.append(name)\n",
    "regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us work slowly by each step of this loop:\n",
    "\n",
    "* We first create an empty list where we will store the names of the regions.\n",
    "* We begin a loop over every single row the column containing the names (`ColumnVariableDescription`).\n",
    "* For each name, which is a string, we split it in pieces using `\": \"` as the points in the string where we want to break it, obtaining a list with the resulting pieces. For instance if we have `Europe: Total`, we essentially do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Europe', 'Total']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Europe: Total'.split(': ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We keep the first element, as it contains the name we want to maintain.\n",
    "* In order to build the actual name of the variable, we join it to `\": Total\"`, obtaining the string we want to keep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Europe: Total'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Europe' + ': Total'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We then check that the string we have built is the same as the variable we began with. If so, we save it on the list we created in the beginning. This step is a bit counter-intuitive, but is done to ensure a) that the name of the variable exists, and b) that it is saved only once.\n",
    "\n",
    "Now we have the names, we need to convert them into the codes. There are several ways to go about it, but here we will show one that relies on the indexing capabilities of `pandas`. Essentially we take `birth_orig` and index it on the names of the variables, to then subset it, keeping only those in our list (the variables we want to retain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnVariableCode</th>\n",
       "      <th>ColumnVariableMeasurementUnit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ColumnVariableDescription</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Europe: Total</th>\n",
       "      <td>QS203EW0002</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Africa: Total</th>\n",
       "      <td>QS203EW0032</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Middle East and Asia: Total</th>\n",
       "      <td>QS203EW0045</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Americas and the Caribbean: Total</th>\n",
       "      <td>QS203EW0063</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antarctica and Oceania: Total</th>\n",
       "      <td>QS203EW0072</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ColumnVariableCode  \\\n",
       "ColumnVariableDescription                                  \n",
       "Europe: Total                                QS203EW0002   \n",
       "Africa: Total                                QS203EW0032   \n",
       "Middle East and Asia: Total                  QS203EW0045   \n",
       "The Americas and the Caribbean: Total        QS203EW0063   \n",
       "Antarctica and Oceania: Total                QS203EW0072   \n",
       "\n",
       "                                      ColumnVariableMeasurementUnit  \n",
       "ColumnVariableDescription                                            \n",
       "Europe: Total                                                 Count  \n",
       "Africa: Total                                                 Count  \n",
       "Middle East and Asia: Total                                   Count  \n",
       "The Americas and the Caribbean: Total                         Count  \n",
       "Antarctica and Oceania: Total                                 Count  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the column `ColumnVariableDescription` as the index and keep only those\n",
    "# in the list `regions`\n",
    "subset = birth_orig.set_index('ColumnVariableDescription').reindex(regions)\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Once this is done, all left to do is to retrieve the codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QS203EW0002', 'QS203EW0032', 'QS203EW0045', 'QS203EW0063', 'QS203EW0072']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the column `ColumnVariableCode` in the table `subset`\n",
    "# into a list\n",
    "region_codes = list(subset['ColumnVariableCode'])\n",
    "\n",
    "region_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the same that we hardcoded originally, only it has been entirely picked up by our python code, not by a human."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
